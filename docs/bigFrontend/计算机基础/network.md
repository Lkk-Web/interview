---
group:
  order: 6
order: 1
---

# 计算机网络

| OSI 七层网络模型 | TCP/IP 四层概念模型 |           对应网络协议           |
| :--------------: | :-----------------: | :------------------------------: |
|      应用层      |       应用层        | HTTP、TFTP、FTP、NFS、WAIS、SMTP |
|      表示层      |                     |   Telnet、Rlogin、SNMP、Gopher   |
|      会话层      |                     |               DNS                |
|      传输层      |       传输层        |             TCP、UDP             |
|      网络层      |       网络层        |  IP、ICMP、ARP、RARP、AKP、UUCP  |
|    数据链路层    |     数据链路层      |            FDDI、PPP             |
|      物理层      |                     |           IEEE 802.1A            |

## 1、网络层

## 2、传输层

### 三次握手与四次挥手

## 3、会话层

### 3.1 DNS 解析

DNS 是应用层协议，事实上他是为其他应用层协议工作的，包括不限于 HTTP 和 SMTP 以及 FTP，用于将用户提供的主机名解析为 ip 地址。

具体过程如下：

1. 用户主机上运行着 DNS 的客户端，就是我们的 PC 机或者手机客户端运行着 DNS 客户端了
2. 浏览器将接收到的 url 中抽取出域名字段，就是访问的主机名，比如http://www.baidu.com/ , 并将这个主机名传送给 DNS 应用的客户端
3. DNS 客户机端向 DNS 服务器端发送一份查询报文，报文中包含着要访问的主机名字段（中间包括一些列缓存查询以及分布式 DNS 集群的工作）

   - 如果要查询的域名，不由`本地 DNS 服务器`区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。如果本地 DNS 服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地 DNS 就把请求发至 13 台根 DNS，根 DNS 服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个 IP。本地 DNS 服务器收到 IP 信息后，将会联系负责.com 域的这台服务器。这台负责.com 域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com 域的下一级 DNS 服务器地址给本地 DNS 服务器。当本地 DNS 服务器收到这个地址后，就会找`http://qq.com`域服务器，重复上面的动作，进行查询，直至找到`www.qq.com` 主机。

4. 该 DNS 客户机最终会收到一份回答报文，其中包含有该主机名对应的 IP 地址
5. 一旦该浏览器收到来自 DNS 的 IP 地址，就可以向该 IP 地址定位的 HTTP 服务器发起 TCP 连接

## 4、应用层

### 4.1 http 状态码

| 分类  | 分类描述                                       |
| :---- | :--------------------------------------------- |
| 1\*\* | 信息，服务器收到请求，需要请求者继续执行操作   |
| 2\*\* | 成功，操作被成功接收并处理                     |
| 3\*\* | 重定向，需要进一步的操作以完成请求             |
| 4\*\* | 客户端错误，请求包含语法错误或无法完成请求     |
| 5\*\* | 服务器错误，服务器在处理请求的过程中发生了错误 |

| 状态码 | 状态码英文名称 | 中文描述 |
| :-- | :-- | :-- |
| 100 | Continue | 继续。客户端应继续其请求 |
| 101 | Switching Protocols | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议 |
| 304 | Not Modified | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |
| 400 | Bad Request | 客户端请求的语法错误，服务器无法理解 |
| 401 | Unauthorized | 请求要求用户的身份认证 |

6、跨域(JSONP)

**协议 域名 端口号 三者有一者不一致就是跨域**

一般用 CORS，后端开启响应体设置，`ACCESS-Control-Allow-Origin：*` //表示允许任何域向我们的服务端提交请求 app.enableCors(); //Nestjs

JSONP 原理：① 自动生成 script，script.src 防止跨域（只能用于 GET） ② 生成的格式为 JSONP，需要 pending 处理函数来处理格式，

### 4.2 http1.0、http1.1、http2.0、http3.0

HTTP0.9：诞生于 1991 年，是 HTTP 的最初版

- 请求只支持 GET，响应只能返回 HTML 文本数据

HTTP1.0：

- 浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接

HTTP1.1：

- 引入了持久连接，即 TCP 连接默认不关闭，可以被多个请求复用
- 在同一个 TCP 连接里面，客户端可以同时发送多个请求
- 虽然允许复用 TCP 连接，但是同一个 TCP 连接里面，所有的数据通信是按次序进行的，服务器只有处理完一个请求，才会接着处理下一个请求。如果前面的处理特别慢，后面就会有许多请求排队等着
- 新增了一些请求方法
- 新增了一些请求头和响应头（如：`cache-control`）

HTTP2.0：

- 采用二进制格式而非文本格式
- 完全多路复用，而非有序并阻塞的、只需一个连接即可实现并行
- 使用报头压缩，降低开销服务器推送

http3.0：

- 基于 google 的 QUIC 协议，而 quic 协议是使用 udp 实现的
- 减少了 tcp 三次握手时间，以及 tls 握手时间
- 解决了 http 2.0 中前一个 stream 丢包导致后一个 stream 被阻塞的问题
- 优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗
- 连接迁移，不再用 tcp 四元组确定一个连接，而是用一个 64 位随机数来确定这个连接
- 更合适的流量控制

##### http1.0

HTTP 1.0 浏览器与服务器只保持短暂的连接，每次请求都需要与服务器建立一个 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求，简单来讲，每次与服务器交互，都需要新开一个连接,而且会导致队头阻塞(head of line blocking)

例如，解析 html 文件，当发现文件中存在资源文件的时候，这时候又创建单独的链接

最终导致，一个 html 文件的访问包含了多次的请求和响应，每次请求都需要创建连接、关系连接，这种形式明显造成了`性能上的缺陷`

如果需要建立长连接，需要在`相应头`设置一个非标准的 Connection 字段 `Connection: keep-alive`

##### http1.1

在 HTTP1.1 中，默认支持长连接（`Connection: keep-alive`），即在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟，建立一次连接，多次请求均由这个连接完成。

如果客户端想关闭 HTTP 连接，可以在`请求头`中携带 `Connection:false` 来告知服务器关闭请求。

HTTP1.1 支持请求`管道化(pipelining)`。管线化使得请求能够“并行”传输。基于 HTTP1.1 的长连接，使得请求管线化成为可能。

例如：

假如响应的主体是一个 html 页面，页面中包含了很多 img，这个时候 keep-alive 就了很大作用。能够“并行”发送多个请求。(注意，这里的“并行”并不是真正意义上的并行传输)

需要注意的是：服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。也就是说，HTTP 管道化可以让我们把先进先出队列从客户端(请求队列)迁移到服务端(响应队列) 如果，客户端同时发了两个请求分别获取 html 和 css，假如说服务器的 css 资源先准备就绪，服务器也会先发送 html，再发送 css。 换句话来说，只有等到 html 响应的资源完全传输完毕后，css 响应的资源才开始传输，不允许同时存在两个并行的响应。

可见，HTTP1.1 还是无法解决队头阻塞(head of line blocking)的问题。同时“管道化”技术存在各种各样的问题，所以很多浏览器要么根本不支持它，要么直接默认关闭，并且开启的条件很苛刻……而且好像实际也没有什么用处。

- 缓存处理 — 强缓存、协商缓存，启发式缓存(新增)

此外，HTTP1.1 还加入了缓存处理(强缓存和协商缓存)，新的字段如 `cache-control`，支持`断点传输`，以及增加了 Host 字段(使得在一台 WEB 服务器上可以在同一个 IP 地址和端口号上使用不同的主机名来创建多个虚拟 WEB 站点)

##### http2.0

- 二进制分帧

HTTP2.0 通过在应用层和传输层之间增加一个二进制分层帧，突破了 HTTP1.1 的性能限制，改进传输性能。

- 多路复用(链接共享) — 真并行传输

  - 流(stream)：已建立连接上的双向字节流。
  - 消息：与逻辑消息对应的完整的一系列数据帧。
  - 帧(frame)：HTTP2.0 通信的最小单位，每个帧包含头部，至少也会标识出当前所属的流(stream_id)

所有 HTTP2.0 通信都在一个 TCP 链接上完成，这个链接可以承载任意流量的双向数据流。每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识符(Stream_id)重新封装。

`多路复用(连接共享)`可能会导致关键字被阻塞，HTTP2.0 里每个数据流都可以设置优先级和依赖，优先级高的数据流会被服务器优先处理和返回客户端，数据流还可以依赖其他的子数据流。

可见，HTTP2.0 实现了真正的并行传输，它能够在一个 TCP 上进行任意数量的 HTTP 请求。而这个强大的功能基于“二级制分帧”的特性。

- 头部压缩

在 HTTP1.X 中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加 500-8000 字节的负荷。

比如 cookie，默认情况下，浏览器会在每次请求的时候，把 cookie 附在 header 上面发给服务器。

HTTP2.0 使用`encoder`来减少需要传输的 header 大小，通讯双方各自**cache 一份 header_files 表**，既避免重复 header 的传输，又减少了需要传输的大小。

高效的压缩算法可以很大的压缩 header，减少发送包的数量从而降低延迟。

- 服务器推送

服务器除了最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确的需求

##### http3.0

Google 搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上。HTTP/3 之前的名称为 HTTP-over-QUIC,2018 年 11 月 7 日宣布新名称是 HTTP/3!

###### 0-RTT — QUIC 协议相比 HTTP2.0 的最大优势

缓存当前会话的上下文，下次恢复会话的时候，只需要将之前的缓存传递给服务器，验证通过，就可以进行传输了。

什么是 0-RTT 建连?

    传输层 0-RTT 就能建立连接
    加密层 0-RTT 就能建立加密连接

- 多路复用

QUIC 基于 UDP，一个连接上的多个 stream 之间没有依赖，即使丢包，只需要重发丢失的包即可，不需要重传整个连接。

- 更好的移动端表现

QUIC 在移动端的表现比 TCP 好，因为 TCP 是基于 IP 识别连接，而 QUIC 是通过 ID 识别链接。 无论网络环境如何变化，只要 ID 不便，就能迅速重新连上。

- 加密认证的根文 — 武装到牙齿

`TCP` 协议头没有经过任何加密和认证，在传输过程中很容易被中间网络设备篡改、注入和窃听。`QUIC` 的 packet 可以说武装到了牙齿，除了个别报文，比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。所以只要对 QUIC 做任何更改，接收端都能及时发现，有效地降低了安全风险。

- 向前纠错机制

QUIC 协议有一个非常独特的特性，称为向前纠错(Foward Error Connec，FEC)，每个数据包除了它本身的内容之外还包括了其他数据包的数据，因此少量的丢包可以通过`其他包的冗余数据直接组装`而无需重传。

向前纠错牺牲了每个数据包可以发送数据的上限，但是带来的提升大于丢包导致的数据重传，因为数据重传将会消耗更多的时间(包括确认数据包丢失，请求重传，等待新数据包等步骤的时间消耗)。

例如：

我总共发送三个包，协议会算出这个三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。当其中出现了非校验包丢失的情况，可以通过另外三个包计算出丢失的数据包的内容。当然这种技术只能使用在丢失一个包的情况下，**如果出现丢失多个包，就不能使用纠错机制了，只能使用重传的方式了**。

> 为什么要有 HTTP3.0?HTTP/2 底层 TCP 的局限带来的问题？

由于 HTTP/2 使用了多路复用，一般来说，同一个域名下只需要使用一个 TCP 链接，但当这个连接中出现了丢包的情况，就会导致 HTTP/2 的表现情况反倒不如 HTTP/2 了。

原因是： 在出现`丢包`的额情况下，整个 TCP 都要开始`等待重传`，导致后面的所有数据都被阻塞。

但是对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况只会影响其中一个连接，剩余的 TCP 链接还可以正常传输数据。

由于修改 TCP 协议是不可能完成的任务。

> 如何在 Chrome 中启用 QUIC 协议

MTF 在资源服务器和内容分发节点都已经启用了 HTTP3.0 协议，根据 用户浏览器 向下兼容，强烈建议您在 Chrome 浏览器开启实验性 `QUICK 协议`支持，体验加速效果：

在浏览器地址栏：输入 chrome://flags

找到 Experimental QUIC protocol，将 Default 改为 Enabled

### 4.3 http request

- 幂等性:是指无论调用这个 URL 多少次，都不会有不同的结果的 HTTP 方法

> 值得注意，幂等性指的是作用于结果而非资源本身。可能某个方法可能每次会得到不同的返回内容，但并不影响资源，这样的也满足幂等性，例如 get 服务器当前时间

| 请求方法 | 幂等性 | 浏览器回退 | 安全性 | TCP |
| :-: | :-: | :-: | :-: | :-: |
| Get | 用于获取资源，不管调用多少次接口，结果都不会改变，所以是幂等的。 | 相对安全性较差，会被浏览器主动缓存 | 数据会携带在地址栏中，长度限制：2083 字节(2K+35) | 产生一个 TCP 数据包，head 和 data 一起发送 |
| Post | 它会对资源本身产生影响，每次调用都会有新的资源产生，因此不满足幂等性 | 回退重新请求 | 数据放置在 HTTP 请求包的包体中，不会直接暴露给用户 | 产生两个 TCP 数据包，header 先发送，服务器响应 100ms 然后继续，发送 data，服务器 200 然后返回数据 |
| Put | 直接把实体部分数据替换到了服务器的资源，但我们多次调用它时，只会产生一次影响，即有相同结果的 HTTP 方法，所有满足幂等性 | 回退重新请求 | 数据放置在 HTTP 请求包的包体中，不会直接暴露给用户 |
| Delete | 用于删除资源，会将资源删除，但调用一次和调用多次的影响是相同的，因此也满足幂等性 | 回退重新请求 | 数据放置在 HTTP 请求包的包体中，不会直接暴露给用户 |

服务器处理长 URL 要消耗比较多的资源，为了性能和安全考虑，会给 URL 长度加限制
